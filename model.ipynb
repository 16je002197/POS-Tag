{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\Banipreet\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     C:\\Users\\Banipreet\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import sys\n",
    "import numpy as np\n",
    "nltk.download('brown')\n",
    "nltk.download('universal_tagset')\n",
    "data = nltk.corpus.brown.tagged_sents(tagset='universal')\n",
    "all_tags = ['#EOS#','#UNK#','ADV', 'NOUN', 'ADP', 'PRON', 'DET', '.', 'PRT', 'VERB', 'X', 'NUM', 'CONJ', 'ADJ']\n",
    "\n",
    "data = np.array([ [(word.lower(),tag) for word,tag in sentence] for sentence in data ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Banipreet\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "train_data,test_data = train_test_split(data,test_size=0.25,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><td>DET</td><td>NOUN</td><td>VERB</td><td>PRON</td><td>VERB</td><td>VERB</td><td>ADP</td><td>ADJ</td><td>ADP</td><td>NOUN</td><td>NOUN</td><td>CONJ</td><td>NOUN</td><td>NOUN</td><td>.</td><td>VERB</td><td>ADJ</td><td>CONJ</td><td>ADJ</td><td>CONJ</td><td>ADV</td><td>ADJ</td><td>.</td><td>.</td></tr><td>the</td><td>jury</td><td>said</td><td>it</td><td>did</td><td>find</td><td>that</td><td>many</td><td>of</td><td>georgia's</td><td>registration</td><td>and</td><td>election</td><td>laws</td><td>``</td><td>are</td><td>outmoded</td><td>or</td><td>inadequate</td><td>and</td><td>often</td><td>ambiguous</td><td>''</td><td>.</td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td>PRON</td><td>VERB</td><td>ADP</td><td>DET</td><td>ADJ</td><td>NOUN</td><td>.</td><td>VERB</td><td>VERB</td><td>NOUN</td><td>CONJ</td><td>VERB</td><td>DET</td><td>ADJ</td><td>NOUN</td><td>ADP</td><td>ADP</td><td>DET</td><td>ADJ</td><td>NOUN</td><td>ADP</td><td>DET</td><td>NOUN</td><td>VERB</td><td>VERB</td><td>VERB</td><td>.</td><td>.</td></tr><td>it</td><td>urged</td><td>that</td><td>the</td><td>next</td><td>legislature</td><td>``</td><td>provide</td><td>enabling</td><td>funds</td><td>and</td><td>re-set</td><td>the</td><td>effective</td><td>date</td><td>so</td><td>that</td><td>an</td><td>orderly</td><td>implementation</td><td>of</td><td>the</td><td>law</td><td>may</td><td>be</td><td>effected</td><td>''</td><td>.</td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import HTML, display\n",
    "def draw(sentence):\n",
    "    words,tags = zip(*sentence)\n",
    "    display(HTML('<table><tr>{tags}</tr>{words}<tr></table>'.format(\n",
    "                words = '<td>{}</td>'.format('</td><td>'.join(words)),\n",
    "                tags = '<td>{}</td>'.format('</td><td>'.join(tags)))))\n",
    "    \n",
    "\n",
    "draw(data[4])\n",
    "draw(data[12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "word_counts = Counter()\n",
    "for sentence in data:\n",
    "    words,tags = zip(*sentence)\n",
    "    word_counts.update(words)\n",
    "\n",
    "all_words = ['#EOS#','#UNK#']+list(list(zip(*word_counts.most_common(10000)))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "word_to_id = defaultdict(lambda:1,{word:i for i,word in enumerate(all_words)})\n",
    "tag_to_id = {tag:i for i,tag in enumerate(all_tags)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_matrix(lines,token_to_id,max_len=None,pad=0,dtype='int32',time_major=False):\n",
    "    \"\"\"Converts a list of names into rnn-digestable matrix with paddings added after the end\"\"\"\n",
    "    \n",
    "    max_len = max_len or max(map(len,lines))\n",
    "    matrix = np.empty([len(lines),max_len],dtype)\n",
    "    matrix.fill(pad)\n",
    "\n",
    "    for i in range(len(lines)):\n",
    "        line_ix = list(map(token_to_id.__getitem__,lines[i]))[:max_len]\n",
    "        matrix[i,:len(line_ix)] = line_ix\n",
    "\n",
    "    return matrix.T if time_major else matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word ids:\n",
      "[[   2 3057    5    2 2238 1334 4238 2454    3    6   19   26 1070   69\n",
      "     8 2088    6    3    1    3  266   65  342    2    1    3    2  315\n",
      "     1    9   87  216 3322   69 1558    4    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0]\n",
      " [  45   12    8  511 8419    6   60 3246   39    2    1    1    3    2\n",
      "   845    1    3    1    3   10 9910    2    1 3470    9   43    1    1\n",
      "     3    6    2 1046  385   73 4562    3    9    2    1    1 3250    3\n",
      "    12   10    2  861 5240   12    8 8936  121    1    4]\n",
      " [  33   64   26   12  445    7 7346    9    8 3337    3    1 2811    3\n",
      "     2  463  572    2    1    1 1649   12    1    4    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0]]\n",
      "Tag ids:\n",
      "[[ 6  3  4  6  3  3  9  9  7 12  4  5  9  4  6  3 12  7  9  7  9  8  4  6\n",
      "   3  7  6 13  3  4  6  3  9  4  3  7  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0]\n",
      " [ 5  9  6  9  3 12  6  3  7  6 13  3  7  6 13  3  7 13  7  5  9  6  3  3\n",
      "   4  6 13  3  7 12  6  3  6 13  3  7  4  6  3  9  3  7  9  4  6 13  3  9\n",
      "   6  3  2 13  7]\n",
      " [ 4  6  5  9 13  4  3  4  6 13  7 13  3  7  6  3  4  6 13  3  3  9  9  7\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "batch_words,batch_tags = zip(*[zip(*sentence) for sentence in data[-3:]])\n",
    "\n",
    "print(\"Word ids:\")\n",
    "print(to_matrix(batch_words,word_to_id))\n",
    "print(\"Tag ids:\")\n",
    "print(to_matrix(batch_tags,tag_to_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Banipreet\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import keras.layers as L\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(L.InputLayer([None],dtype='int32'))\n",
    "model.add(L.Embedding(len(all_words),50))\n",
    "model.add(L.SimpleRNN(64,return_sequences=True))\n",
    "\n",
    "#add top layer that predicts tag probabilities\n",
    "stepwise_dense = L.Dense(len(all_tags),activation='softmax')\n",
    "stepwise_dense = L.TimeDistributed(stepwise_dense)\n",
    "model.add(stepwise_dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "BATCH_SIZE=32\n",
    "def generate_batches(sentences,batch_size=BATCH_SIZE,max_len=None,pad=0):\n",
    "    assert isinstance(sentences,np.ndarray),\"Make sure sentences is q numpy array\"\n",
    "    \n",
    "    while True:\n",
    "        indices = np.random.permutation(np.arange(len(sentences)))\n",
    "        for start in range(0,len(indices)-1,batch_size):\n",
    "            batch_indices = indices[start:start+batch_size]\n",
    "            batch_words,batch_tags = [],[]\n",
    "            for sent in sentences[batch_indices]:\n",
    "                words,tags = zip(*sent)\n",
    "                batch_words.append(words)\n",
    "                batch_tags.append(tags)\n",
    "\n",
    "            batch_words = to_matrix(batch_words,word_to_id,max_len,pad)\n",
    "            batch_tags = to_matrix(batch_tags,tag_to_id,max_len,pad)\n",
    "\n",
    "            batch_tags_1hot = to_categorical(batch_tags,len(all_tags)).reshape(batch_tags.shape+(-1,))\n",
    "            yield batch_words,batch_tags_1hot\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_test_accuracy(model):\n",
    "    test_words,test_tags = zip(*[zip(*sentence) for sentence in test_data])\n",
    "    test_words,test_tags = to_matrix(test_words,word_to_id),to_matrix(test_tags,tag_to_id)\n",
    "\n",
    "    #predict tag probabilities of shape [batch,time,n_tags]\n",
    "    predicted_tag_probabilities = model.predict(test_words,verbose=1)\n",
    "    predicted_tags = predicted_tag_probabilities.argmax(axis=-1)\n",
    "\n",
    "    #compute accurary excluding padding\n",
    "    numerator = np.sum(np.logical_and((predicted_tags == test_tags),(test_words != 0)))\n",
    "    denominator = np.sum(test_words != 0)\n",
    "    return float(numerator)/denominator\n",
    "\n",
    "\n",
    "class EvaluateAccuracy(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self,epoch,logs=None):\n",
    "        sys.stdout.flush()\n",
    "        print(\"\\nMeasuring validation accuracy...\")\n",
    "        acc = compute_test_accuracy(self.model)\n",
    "        print(\"\\nValidation accuracy: %.5f\\n\"%acc)\n",
    "        sys.stdout.flush()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1344/1343 [==============================] - 77s 57ms/step - loss: 0.2377\n",
      "\n",
      "Measuring validation accuracy...\n",
      "14335/14335 [==============================] - 15s 1ms/step\n",
      "\n",
      "Validation accuracy: 0.93969\n",
      "\n",
      "Epoch 2/5\n",
      "1344/1343 [==============================] - 82s 61ms/step - loss: 0.0579\n",
      "\n",
      "Measuring validation accuracy...\n",
      "14335/14335 [==============================] - 14s 1ms/step\n",
      "\n",
      "Validation accuracy: 0.94471\n",
      "\n",
      "Epoch 3/5\n",
      "1344/1343 [==============================] - 75s 56ms/step - loss: 0.0510\n",
      "\n",
      "Measuring validation accuracy...\n",
      "14335/14335 [==============================] - 15s 1ms/step\n",
      "\n",
      "Validation accuracy: 0.94619\n",
      "\n",
      "Epoch 4/5\n",
      "1344/1343 [==============================] - 72s 53ms/step - loss: 0.0467\n",
      "\n",
      "Measuring validation accuracy...\n",
      "14335/14335 [==============================] - 14s 998us/step\n",
      "\n",
      "Validation accuracy: 0.94688\n",
      "\n",
      "Epoch 5/5\n",
      "1344/1343 [==============================] - 70s 52ms/step - loss: 0.0432\n",
      "\n",
      "Measuring validation accuracy...\n",
      "14335/14335 [==============================] - 13s 924us/step\n",
      "\n",
      "Validation accuracy: 0.94594\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28eef9c5160>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile('adam','categorical_crossentropy')\n",
    "\n",
    "model.fit_generator(generate_batches(train_data),len(train_data)/BATCH_SIZE,\n",
    "                    callbacks=[EvaluateAccuracy()], epochs=5,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14335/14335 [==============================] - 15s 1ms/step\n",
      "Simple RNN accuracy: 0.94594\n"
     ]
    }
   ],
   "source": [
    "acc = compute_test_accuracy(model)\n",
    "print(\"Simple RNN accuracy: %.5f\"%acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bidirectional SimpleRNN\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(L.InputLayer([None],dtype='int32'))\n",
    "model.add(L.Embedding(len(all_words),50))\n",
    "model.add(L.Bidirectional(L.SimpleRNN(64,return_sequences=True)))\n",
    "\n",
    "stepwise_dense = L.Dense(len(all_tags),activation='softmax')\n",
    "stepwise_dense = L.TimeDistributed(stepwise_dense)\n",
    "model.add(stepwise_dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1344/1343 [==============================] - 121s 90ms/step - loss: 0.1863\n",
      "\n",
      "Measuring validation accuracy...\n",
      "14335/14335 [==============================] - 26s 2ms/step\n",
      "\n",
      "Validation accuracy: 0.95581\n",
      "\n",
      "Epoch 2/5\n",
      "1344/1343 [==============================] - 116s 87ms/step - loss: 0.0423\n",
      "\n",
      "Measuring validation accuracy...\n",
      "14335/14335 [==============================] - 25s 2ms/step\n",
      "\n",
      "Validation accuracy: 0.95967\n",
      "\n",
      "Epoch 3/5\n",
      "1344/1343 [==============================] - 73s 54ms/step - loss: 0.0352\n",
      "\n",
      "Measuring validation accuracy...\n",
      "14335/14335 [==============================] - 11s 765us/step\n",
      "\n",
      "Validation accuracy: 0.96254\n",
      "\n",
      "Epoch 4/5\n",
      "1344/1343 [==============================] - 52s 39ms/step - loss: 0.0297\n",
      "\n",
      "Measuring validation accuracy...\n",
      "14335/14335 [==============================] - 11s 781us/step\n",
      "\n",
      "Validation accuracy: 0.96152\n",
      "\n",
      "Epoch 5/5\n",
      "1344/1343 [==============================] - 52s 39ms/step - loss: 0.0252\n",
      "\n",
      "Measuring validation accuracy...\n",
      "14335/14335 [==============================] - 11s 789us/step\n",
      "\n",
      "Validation accuracy: 0.96125\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28eed6b4828>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile('adam','categorical_crossentropy')\n",
    "\n",
    "model.fit_generator(generate_batches(train_data),len(train_data)/BATCH_SIZE,\n",
    "                    callbacks=[EvaluateAccuracy()], epochs=5,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14335/14335 [==============================] - 11s 785us/step\n",
      "\n",
      "Bidirectional RNN accuracy: 0.96125\n"
     ]
    }
   ],
   "source": [
    "acc = compute_test_accuracy(model)\n",
    "print(\"\\nBidirectional RNN accuracy: %.5f\"%acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bidirectional LSTM\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(L.InputLayer([None],dtype='int32'))\n",
    "model.add(L.Embedding(len(all_words),50))\n",
    "model.add(L.Bidirectional(L.LSTM(64, return_sequences=True)))\n",
    "#model.add(L.GRU(32,return_sequences=True))\n",
    "#model.add(L.LSTM(16,return_sequences=True))\n",
    "\n",
    "\n",
    "stepwise_dense = L.Dense(len(all_tags),activation='softmax')\n",
    "stepwise_dense = L.TimeDistributed(stepwise_dense)\n",
    "model.add(stepwise_dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1344/1343 [==============================] - 178s 132ms/step - loss: 0.2636\n",
      "\n",
      "Measuring validation accuracy...\n",
      "14335/14335 [==============================] - 37s 3ms/step\n",
      "\n",
      "Validation accuracy: 0.95459\n",
      "\n",
      "Epoch 2/5\n",
      "1344/1343 [==============================] - 178s 133ms/step - loss: 0.0439\n",
      "\n",
      "Measuring validation accuracy...\n",
      "14335/14335 [==============================] - 37s 3ms/step\n",
      "\n",
      "Validation accuracy: 0.96181\n",
      "\n",
      "Epoch 3/5\n",
      "1344/1343 [==============================] - 178s 132ms/step - loss: 0.0363\n",
      "\n",
      "Measuring validation accuracy...\n",
      "14335/14335 [==============================] - 41s 3ms/step\n",
      "\n",
      "Validation accuracy: 0.96364\n",
      "\n",
      "Epoch 4/5\n",
      "1344/1343 [==============================] - 192s 143ms/step - loss: 0.0314\n",
      "\n",
      "Measuring validation accuracy...\n",
      "14335/14335 [==============================] - 38s 3ms/step\n",
      "\n",
      "Validation accuracy: 0.96492\n",
      "\n",
      "Epoch 5/5\n",
      "1344/1343 [==============================] - 185s 138ms/step - loss: 0.0280\n",
      "\n",
      "Measuring validation accuracy...\n",
      "14335/14335 [==============================] - 38s 3ms/step\n",
      "\n",
      "Validation accuracy: 0.96504\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28f994e19b0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile('adam','categorical_crossentropy')\n",
    "\n",
    "model.fit_generator(generate_batches(train_data),len(train_data)/BATCH_SIZE,\n",
    "                    callbacks=[EvaluateAccuracy()], epochs=5,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14335/14335 [==============================] - 38s 3ms/step\n",
      "\n",
      "Bidirectional LSTM accuracy: 0.96504\n"
     ]
    }
   ],
   "source": [
    "acc = compute_test_accuracy(model)\n",
    "print(\"\\nBidirectional LSTM accuracy: %.5f\"%acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
